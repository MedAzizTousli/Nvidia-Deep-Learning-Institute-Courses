{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g-atf3gekcgR"
   },
   "source": [
    "# Assessment 1: I can train and deploy a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_7wkT17FkmU6"
   },
   "source": [
    "At this point, you've worked through a full deep learning workflow. You've loaded a dataset, trained a model, and deployed your model into a simple application. Validate your learning by attempting to replicate that workflow with a new problem.\n",
    "\n",
    "We've included a dataset which consists of two classes:  \n",
    "\n",
    "1) Face: Contains images which include the face of a whale  \n",
    "2) Not Face: Contains images which do not include the face of a whale.  \n",
    "\n",
    "The dataset is located at ```/dli/data/whale/data/train```.\n",
    "\n",
    "Your challenge is:\n",
    "\n",
    "1) Use [DIGITS](/digits) to train a model to identify *new* whale faces with an accuracy of more than 80%.   \n",
    "\n",
    "2) Deploy your model by modifying and saving the python application [submission.py](../../../../edit/tasks/task-assessment/task/submission.py) to return the word \"whale\" if the image contains a whale's face and \"not whale\" if the image does not.  \n",
    "\n",
    "Resources:\n",
    "\n",
    "1) [Train a model](../../task1/task/Train%20a%20Model.ipynb)  \n",
    "2) [New Data as a goal](../../task2/task/New%20Data%20as%20a%20Goal.ipynb)  \n",
    "3) [Deployment](../../task3/task/Deployment.ipynb)  \n",
    "\n",
    "Suggestions: \n",
    "\n",
    "- Use empty code blocks to find out any informantion necessary to solve this problem: eg: ```!ls [directorypath] prints the files in a given directory``` \n",
    "- Executing the first two cells below will run your python script with test images, the first should return \"whale\" and the second should return \"not whale\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YaaY1Vb3o3mC"
   },
   "source": [
    "Start in [DIGITS](/digits/). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0404 08:30:36.235911   220 gpu_memory.cpp:105] GPUMemory::Manager initialized\n",
      "I0404 08:30:36.236682   220 gpu_memory.cpp:107] Total memory: 11996954624, Free: 11790385152, dev_info[0]: total=11996954624 free=11790385152\n",
      "W0404 08:30:36.236747   220 _caffe.cpp:172] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0404 08:30:36.236871   220 _caffe.cpp:173] Use this instead (with the named \"weights\" parameter):\n",
      "W0404 08:30:36.236884   220 _caffe.cpp:175] Net('/dli/data/digits/20190404-082321-ad38/deploy.prototxt', 1, weights='/dli/data/digits/20190404-082321-ad38/snapshot_iter_270.caffemodel')\n",
      "I0404 08:30:36.237226   220 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /dli/data/digits/20190404-082321-ad38/deploy.prototxt\n",
      "I0404 08:30:36.237260   220 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.\n",
      "W0404 08:30:36.237272   220 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.\n",
      "I0404 08:30:36.247190   220 net.cpp:79] Initializing net from parameters: \n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"input\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 1\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"conv3\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc8\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc8\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"softmax\"\n",
      "  type: \"Softmax\"\n",
      "  bottom: \"fc8\"\n",
      "  top: \"softmax\"\n",
      "}\n",
      "I0404 08:30:36.247601   220 net.cpp:109] Using FLOAT as default forward math type\n",
      "I0404 08:30:36.247619   220 net.cpp:115] Using FLOAT as default backward math type\n",
      "I0404 08:30:36.247633   220 layer_factory.hpp:172] Creating layer 'input' of type 'Input'\n",
      "I0404 08:30:36.247647   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:36.247668   220 net.cpp:199] Created Layer input (0)\n",
      "I0404 08:30:36.247689   220 net.cpp:541] input -> data\n",
      "I0404 08:30:36.248404   220 net.cpp:259] Setting up input\n",
      "I0404 08:30:36.248442   220 net.cpp:266] TEST Top shape for layer 0 'input' 1 3 227 227 (154587)\n",
      "I0404 08:30:36.248466   220 layer_factory.hpp:172] Creating layer 'conv1' of type 'Convolution'\n",
      "I0404 08:30:36.248478   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:36.248517   220 net.cpp:199] Created Layer conv1 (1)\n",
      "I0404 08:30:36.248533   220 net.cpp:571] conv1 <- data\n",
      "I0404 08:30:36.248548   220 net.cpp:541] conv1 -> conv1\n",
      "I0404 08:30:36.778499   220 net.cpp:259] Setting up conv1\n",
      "I0404 08:30:36.778554   220 net.cpp:266] TEST Top shape for layer 1 'conv1' 1 96 55 55 (290400)\n",
      "I0404 08:30:36.778589   220 layer_factory.hpp:172] Creating layer 'relu1' of type 'ReLU'\n",
      "I0404 08:30:36.778606   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:36.778622   220 net.cpp:199] Created Layer relu1 (2)\n",
      "I0404 08:30:36.778635   220 net.cpp:571] relu1 <- conv1\n",
      "I0404 08:30:36.778643   220 net.cpp:526] relu1 -> conv1 (in-place)\n",
      "I0404 08:30:36.778671   220 net.cpp:259] Setting up relu1\n",
      "I0404 08:30:36.778683   220 net.cpp:266] TEST Top shape for layer 2 'relu1' 1 96 55 55 (290400)\n",
      "I0404 08:30:36.778690   220 layer_factory.hpp:172] Creating layer 'norm1' of type 'LRN'\n",
      "I0404 08:30:36.778702   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:36.778725   220 net.cpp:199] Created Layer norm1 (3)\n",
      "I0404 08:30:36.778736   220 net.cpp:571] norm1 <- conv1\n",
      "I0404 08:30:36.778743   220 net.cpp:541] norm1 -> norm1\n",
      "I0404 08:30:36.778805   220 net.cpp:259] Setting up norm1\n",
      "I0404 08:30:36.778822   220 net.cpp:266] TEST Top shape for layer 3 'norm1' 1 96 55 55 (290400)\n",
      "I0404 08:30:36.778829   220 layer_factory.hpp:172] Creating layer 'pool1' of type 'Pooling'\n",
      "I0404 08:30:36.778841   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:36.778887   220 net.cpp:199] Created Layer pool1 (4)\n",
      "I0404 08:30:36.778900   220 net.cpp:571] pool1 <- norm1\n",
      "I0404 08:30:36.778908   220 net.cpp:541] pool1 -> pool1\n",
      "I0404 08:30:36.779000   220 net.cpp:259] Setting up pool1\n",
      "I0404 08:30:36.779018   220 net.cpp:266] TEST Top shape for layer 4 'pool1' 1 96 27 27 (69984)\n",
      "I0404 08:30:36.779028   220 layer_factory.hpp:172] Creating layer 'conv2' of type 'Convolution'\n",
      "I0404 08:30:36.779042   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:36.779065   220 net.cpp:199] Created Layer conv2 (5)\n",
      "I0404 08:30:36.779076   220 net.cpp:571] conv2 <- pool1\n",
      "I0404 08:30:36.779084   220 net.cpp:541] conv2 -> conv2\n",
      "I0404 08:30:36.786151   220 net.cpp:259] Setting up conv2\n",
      "I0404 08:30:36.786182   220 net.cpp:266] TEST Top shape for layer 5 'conv2' 1 256 27 27 (186624)\n",
      "I0404 08:30:36.786206   220 layer_factory.hpp:172] Creating layer 'relu2' of type 'ReLU'\n",
      "I0404 08:30:36.786221   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:36.786232   220 net.cpp:199] Created Layer relu2 (6)\n",
      "I0404 08:30:36.786245   220 net.cpp:571] relu2 <- conv2\n",
      "I0404 08:30:36.786252   220 net.cpp:526] relu2 -> conv2 (in-place)\n",
      "I0404 08:30:36.786269   220 net.cpp:259] Setting up relu2\n",
      "I0404 08:30:36.786278   220 net.cpp:266] TEST Top shape for layer 6 'relu2' 1 256 27 27 (186624)\n",
      "I0404 08:30:36.786289   220 layer_factory.hpp:172] Creating layer 'norm2' of type 'LRN'\n",
      "I0404 08:30:36.786295   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:36.786315   220 net.cpp:199] Created Layer norm2 (7)\n",
      "I0404 08:30:36.786326   220 net.cpp:571] norm2 <- conv2\n",
      "I0404 08:30:36.786334   220 net.cpp:541] norm2 -> norm2\n",
      "I0404 08:30:36.786391   220 net.cpp:259] Setting up norm2\n",
      "I0404 08:30:36.786407   220 net.cpp:266] TEST Top shape for layer 7 'norm2' 1 256 27 27 (186624)\n",
      "I0404 08:30:36.786418   220 layer_factory.hpp:172] Creating layer 'pool2' of type 'Pooling'\n",
      "I0404 08:30:36.786430   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:36.786450   220 net.cpp:199] Created Layer pool2 (8)\n",
      "I0404 08:30:36.786459   220 net.cpp:571] pool2 <- norm2\n",
      "I0404 08:30:36.786470   220 net.cpp:541] pool2 -> pool2\n",
      "I0404 08:30:36.786530   220 net.cpp:259] Setting up pool2\n",
      "I0404 08:30:36.786547   220 net.cpp:266] TEST Top shape for layer 8 'pool2' 1 256 13 13 (43264)\n",
      "I0404 08:30:36.786561   220 layer_factory.hpp:172] Creating layer 'conv3' of type 'Convolution'\n",
      "I0404 08:30:36.786571   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:36.786588   220 net.cpp:199] Created Layer conv3 (9)\n",
      "I0404 08:30:36.786600   220 net.cpp:571] conv3 <- pool2\n",
      "I0404 08:30:36.786607   220 net.cpp:541] conv3 -> conv3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0404 08:30:36.803944   220 net.cpp:259] Setting up conv3\n",
      "I0404 08:30:36.803983   220 net.cpp:266] TEST Top shape for layer 9 'conv3' 1 384 13 13 (64896)\n",
      "I0404 08:30:36.804008   220 layer_factory.hpp:172] Creating layer 'relu3' of type 'ReLU'\n",
      "I0404 08:30:36.804023   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:36.804039   220 net.cpp:199] Created Layer relu3 (10)\n",
      "I0404 08:30:36.804050   220 net.cpp:571] relu3 <- conv3\n",
      "I0404 08:30:36.804064   220 net.cpp:526] relu3 -> conv3 (in-place)\n",
      "I0404 08:30:36.804081   220 net.cpp:259] Setting up relu3\n",
      "I0404 08:30:36.804092   220 net.cpp:266] TEST Top shape for layer 10 'relu3' 1 384 13 13 (64896)\n",
      "I0404 08:30:36.804105   220 layer_factory.hpp:172] Creating layer 'conv4' of type 'Convolution'\n",
      "I0404 08:30:36.804116   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:36.804141   220 net.cpp:199] Created Layer conv4 (11)\n",
      "I0404 08:30:36.804152   220 net.cpp:571] conv4 <- conv3\n",
      "I0404 08:30:36.804168   220 net.cpp:541] conv4 -> conv4\n",
      "I0404 08:30:36.816640   220 net.cpp:259] Setting up conv4\n",
      "I0404 08:30:36.816669   220 net.cpp:266] TEST Top shape for layer 11 'conv4' 1 384 13 13 (64896)\n",
      "I0404 08:30:36.816712   220 layer_factory.hpp:172] Creating layer 'relu4' of type 'ReLU'\n",
      "I0404 08:30:36.816722   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:36.816736   220 net.cpp:199] Created Layer relu4 (12)\n",
      "I0404 08:30:36.816748   220 net.cpp:571] relu4 <- conv4\n",
      "I0404 08:30:36.816761   220 net.cpp:526] relu4 -> conv4 (in-place)\n",
      "I0404 08:30:36.816776   220 net.cpp:259] Setting up relu4\n",
      "I0404 08:30:36.816789   220 net.cpp:266] TEST Top shape for layer 12 'relu4' 1 384 13 13 (64896)\n",
      "I0404 08:30:36.816802   220 layer_factory.hpp:172] Creating layer 'conv5' of type 'Convolution'\n",
      "I0404 08:30:36.816812   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:36.816836   220 net.cpp:199] Created Layer conv5 (13)\n",
      "I0404 08:30:36.816848   220 net.cpp:571] conv5 <- conv4\n",
      "I0404 08:30:36.816860   220 net.cpp:541] conv5 -> conv5\n",
      "I0404 08:30:36.824977   220 net.cpp:259] Setting up conv5\n",
      "I0404 08:30:36.825002   220 net.cpp:266] TEST Top shape for layer 13 'conv5' 1 256 13 13 (43264)\n",
      "I0404 08:30:36.825021   220 layer_factory.hpp:172] Creating layer 'relu5' of type 'ReLU'\n",
      "I0404 08:30:36.825033   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:36.825044   220 net.cpp:199] Created Layer relu5 (14)\n",
      "I0404 08:30:36.825055   220 net.cpp:571] relu5 <- conv5\n",
      "I0404 08:30:36.825062   220 net.cpp:526] relu5 -> conv5 (in-place)\n",
      "I0404 08:30:36.825078   220 net.cpp:259] Setting up relu5\n",
      "I0404 08:30:36.825085   220 net.cpp:266] TEST Top shape for layer 14 'relu5' 1 256 13 13 (43264)\n",
      "I0404 08:30:36.825098   220 layer_factory.hpp:172] Creating layer 'pool5' of type 'Pooling'\n",
      "I0404 08:30:36.825103   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:36.825120   220 net.cpp:199] Created Layer pool5 (15)\n",
      "I0404 08:30:36.825131   220 net.cpp:571] pool5 <- conv5\n",
      "I0404 08:30:36.825137   220 net.cpp:541] pool5 -> pool5\n",
      "I0404 08:30:36.825209   220 net.cpp:259] Setting up pool5\n",
      "I0404 08:30:36.825227   220 net.cpp:266] TEST Top shape for layer 15 'pool5' 1 256 6 6 (9216)\n",
      "I0404 08:30:36.825237   220 layer_factory.hpp:172] Creating layer 'fc6' of type 'InnerProduct'\n",
      "I0404 08:30:36.825248   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:36.825261   220 net.cpp:199] Created Layer fc6 (16)\n",
      "I0404 08:30:36.825273   220 net.cpp:571] fc6 <- pool5\n",
      "I0404 08:30:36.825279   220 net.cpp:541] fc6 -> fc6\n",
      "I0404 08:30:37.502573   220 net.cpp:259] Setting up fc6\n",
      "I0404 08:30:37.502626   220 net.cpp:266] TEST Top shape for layer 16 'fc6' 1 4096 (4096)\n",
      "I0404 08:30:37.502652   220 layer_factory.hpp:172] Creating layer 'relu6' of type 'ReLU'\n",
      "I0404 08:30:37.502667   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:37.502686   220 net.cpp:199] Created Layer relu6 (17)\n",
      "I0404 08:30:37.502699   220 net.cpp:571] relu6 <- fc6\n",
      "I0404 08:30:37.502715   220 net.cpp:526] relu6 -> fc6 (in-place)\n",
      "I0404 08:30:37.502737   220 net.cpp:259] Setting up relu6\n",
      "I0404 08:30:37.502748   220 net.cpp:266] TEST Top shape for layer 17 'relu6' 1 4096 (4096)\n",
      "I0404 08:30:37.502759   220 layer_factory.hpp:172] Creating layer 'drop6' of type 'Dropout'\n",
      "I0404 08:30:37.502770   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:37.502787   220 net.cpp:199] Created Layer drop6 (18)\n",
      "I0404 08:30:37.502797   220 net.cpp:571] drop6 <- fc6\n",
      "I0404 08:30:37.502809   220 net.cpp:526] drop6 -> fc6 (in-place)\n",
      "I0404 08:30:37.537298   220 net.cpp:259] Setting up drop6\n",
      "I0404 08:30:37.537325   220 net.cpp:266] TEST Top shape for layer 18 'drop6' 1 4096 (4096)\n",
      "I0404 08:30:37.537334   220 layer_factory.hpp:172] Creating layer 'fc7' of type 'InnerProduct'\n",
      "I0404 08:30:37.537344   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:37.537366   220 net.cpp:199] Created Layer fc7 (19)\n",
      "I0404 08:30:37.537405   220 net.cpp:571] fc7 <- fc6\n",
      "I0404 08:30:37.537415   220 net.cpp:541] fc7 -> fc7\n",
      "I0404 08:30:37.838807   220 net.cpp:259] Setting up fc7\n",
      "I0404 08:30:37.838861   220 net.cpp:266] TEST Top shape for layer 19 'fc7' 1 4096 (4096)\n",
      "I0404 08:30:37.838884   220 layer_factory.hpp:172] Creating layer 'relu7' of type 'ReLU'\n",
      "I0404 08:30:37.838901   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:37.838917   220 net.cpp:199] Created Layer relu7 (20)\n",
      "I0404 08:30:37.838932   220 net.cpp:571] relu7 <- fc7\n",
      "I0404 08:30:37.838941   220 net.cpp:526] relu7 -> fc7 (in-place)\n",
      "I0404 08:30:37.838961   220 net.cpp:259] Setting up relu7\n",
      "I0404 08:30:37.838973   220 net.cpp:266] TEST Top shape for layer 20 'relu7' 1 4096 (4096)\n",
      "I0404 08:30:37.839002   220 layer_factory.hpp:172] Creating layer 'drop7' of type 'Dropout'\n",
      "I0404 08:30:37.839015   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:37.839031   220 net.cpp:199] Created Layer drop7 (21)\n",
      "I0404 08:30:37.839042   220 net.cpp:571] drop7 <- fc7\n",
      "I0404 08:30:37.839049   220 net.cpp:526] drop7 -> fc7 (in-place)\n",
      "I0404 08:30:37.873761   220 net.cpp:259] Setting up drop7\n",
      "I0404 08:30:37.873819   220 net.cpp:266] TEST Top shape for layer 21 'drop7' 1 4096 (4096)\n",
      "I0404 08:30:37.873836   220 layer_factory.hpp:172] Creating layer 'fc8' of type 'InnerProduct'\n",
      "I0404 08:30:37.873852   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:37.873875   220 net.cpp:199] Created Layer fc8 (22)\n",
      "I0404 08:30:37.873888   220 net.cpp:571] fc8 <- fc7\n",
      "I0404 08:30:37.873900   220 net.cpp:541] fc8 -> fc8\n",
      "I0404 08:30:37.874946   220 net.cpp:259] Setting up fc8\n",
      "I0404 08:30:37.874972   220 net.cpp:266] TEST Top shape for layer 22 'fc8' 1 2 (2)\n",
      "I0404 08:30:37.875013   220 layer_factory.hpp:172] Creating layer 'softmax' of type 'Softmax'\n",
      "I0404 08:30:37.875022   220 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:37.875046   220 net.cpp:199] Created Layer softmax (23)\n",
      "I0404 08:30:37.875059   220 net.cpp:571] softmax <- fc8\n",
      "I0404 08:30:37.875072   220 net.cpp:541] softmax -> softmax\n",
      "I0404 08:30:37.875164   220 net.cpp:259] Setting up softmax\n",
      "I0404 08:30:37.875180   220 net.cpp:266] TEST Top shape for layer 23 'softmax' 1 2 (2)\n",
      "I0404 08:30:37.875191   220 net.cpp:337] softmax does not need backward computation.\n",
      "I0404 08:30:37.875202   220 net.cpp:337] fc8 does not need backward computation.\n",
      "I0404 08:30:37.875213   220 net.cpp:337] drop7 does not need backward computation.\n",
      "I0404 08:30:37.875221   220 net.cpp:337] relu7 does not need backward computation.\n",
      "I0404 08:30:37.875231   220 net.cpp:337] fc7 does not need backward computation.\n",
      "I0404 08:30:37.875236   220 net.cpp:337] drop6 does not need backward computation.\n",
      "I0404 08:30:37.875247   220 net.cpp:337] relu6 does not need backward computation.\n",
      "I0404 08:30:37.875252   220 net.cpp:337] fc6 does not need backward computation.\n",
      "I0404 08:30:37.875263   220 net.cpp:337] pool5 does not need backward computation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0404 08:30:37.875268   220 net.cpp:337] relu5 does not need backward computation.\n",
      "I0404 08:30:37.875279   220 net.cpp:337] conv5 does not need backward computation.\n",
      "I0404 08:30:37.875285   220 net.cpp:337] relu4 does not need backward computation.\n",
      "I0404 08:30:37.875296   220 net.cpp:337] conv4 does not need backward computation.\n",
      "I0404 08:30:37.875301   220 net.cpp:337] relu3 does not need backward computation.\n",
      "I0404 08:30:37.875311   220 net.cpp:337] conv3 does not need backward computation.\n",
      "I0404 08:30:37.875324   220 net.cpp:337] pool2 does not need backward computation.\n",
      "I0404 08:30:37.875334   220 net.cpp:337] norm2 does not need backward computation.\n",
      "I0404 08:30:37.875350   220 net.cpp:337] relu2 does not need backward computation.\n",
      "I0404 08:30:37.875361   220 net.cpp:337] conv2 does not need backward computation.\n",
      "I0404 08:30:37.875372   220 net.cpp:337] pool1 does not need backward computation.\n",
      "I0404 08:30:37.875408   220 net.cpp:337] norm1 does not need backward computation.\n",
      "I0404 08:30:37.875419   220 net.cpp:337] relu1 does not need backward computation.\n",
      "I0404 08:30:37.875430   220 net.cpp:337] conv1 does not need backward computation.\n",
      "I0404 08:30:37.875442   220 net.cpp:337] input does not need backward computation.\n",
      "I0404 08:30:37.875452   220 net.cpp:379] This network produces output softmax\n",
      "I0404 08:30:37.875479   220 net.cpp:402] Top memory (TEST) required for data: 8315264 diff: 8315264\n",
      "I0404 08:30:37.875490   220 net.cpp:405] Bottom memory (TEST) required for data: 8315256 diff: 8315256\n",
      "I0404 08:30:37.875497   220 net.cpp:408] Shared (in-place) memory (TEST) by data: 2665856 diff: 2665856\n",
      "I0404 08:30:37.875507   220 net.cpp:411] Parameters memory (TEST) required for data: 227505672 diff: 227505672\n",
      "I0404 08:30:37.875514   220 net.cpp:414] Parameters shared memory (TEST) by data: 0 diff: 0\n",
      "I0404 08:30:37.875524   220 net.cpp:420] Network initialization done.\n",
      "I0404 08:30:37.984838   220 net.cpp:1129] Ignoring source layer train-data\n",
      "I0404 08:30:37.984885   220 net.cpp:1137] Copying source layer conv1 Type:Convolution #blobs=2\n",
      "I0404 08:30:37.984983   220 net.cpp:1137] Copying source layer relu1 Type:ReLU #blobs=0\n",
      "I0404 08:30:37.984997   220 net.cpp:1137] Copying source layer norm1 Type:LRN #blobs=0\n",
      "I0404 08:30:37.985004   220 net.cpp:1137] Copying source layer pool1 Type:Pooling #blobs=0\n",
      "I0404 08:30:37.985010   220 net.cpp:1137] Copying source layer conv2 Type:Convolution #blobs=2\n",
      "I0404 08:30:37.985179   220 net.cpp:1137] Copying source layer relu2 Type:ReLU #blobs=0\n",
      "I0404 08:30:37.985193   220 net.cpp:1137] Copying source layer norm2 Type:LRN #blobs=0\n",
      "I0404 08:30:37.985198   220 net.cpp:1137] Copying source layer pool2 Type:Pooling #blobs=0\n",
      "I0404 08:30:37.985203   220 net.cpp:1137] Copying source layer conv3 Type:Convolution #blobs=2\n",
      "I0404 08:30:37.985668   220 net.cpp:1137] Copying source layer relu3 Type:ReLU #blobs=0\n",
      "I0404 08:30:37.985683   220 net.cpp:1137] Copying source layer conv4 Type:Convolution #blobs=2\n",
      "I0404 08:30:37.986032   220 net.cpp:1137] Copying source layer relu4 Type:ReLU #blobs=0\n",
      "I0404 08:30:37.986044   220 net.cpp:1137] Copying source layer conv5 Type:Convolution #blobs=2\n",
      "I0404 08:30:37.986284   220 net.cpp:1137] Copying source layer relu5 Type:ReLU #blobs=0\n",
      "I0404 08:30:37.986297   220 net.cpp:1137] Copying source layer pool5 Type:Pooling #blobs=0\n",
      "I0404 08:30:37.986304   220 net.cpp:1137] Copying source layer fc6 Type:InnerProduct #blobs=2\n",
      "I0404 08:30:38.004410   220 net.cpp:1137] Copying source layer relu6 Type:ReLU #blobs=0\n",
      "I0404 08:30:38.004448   220 net.cpp:1137] Copying source layer drop6 Type:Dropout #blobs=0\n",
      "I0404 08:30:38.004462   220 net.cpp:1137] Copying source layer fc7 Type:InnerProduct #blobs=2\n",
      "I0404 08:30:38.012480   220 net.cpp:1137] Copying source layer relu7 Type:ReLU #blobs=0\n",
      "I0404 08:30:38.012507   220 net.cpp:1137] Copying source layer drop7 Type:Dropout #blobs=0\n",
      "I0404 08:30:38.012517   220 net.cpp:1137] Copying source layer fc8 Type:InnerProduct #blobs=2\n",
      "I0404 08:30:38.012548   220 net.cpp:1129] Ignoring source layer loss\n",
      "whale\n"
     ]
    }
   ],
   "source": [
    "!python submission.py '/dli/data/whale/data/train/face/w_1.jpg'  #This should return \"whale\" at the very bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0404 08:30:48.521246   235 gpu_memory.cpp:105] GPUMemory::Manager initialized\n",
      "I0404 08:30:48.521977   235 gpu_memory.cpp:107] Total memory: 11996954624, Free: 11790385152, dev_info[0]: total=11996954624 free=11790385152\n",
      "W0404 08:30:48.522038   235 _caffe.cpp:172] DEPRECATION WARNING - deprecated use of Python interface\n",
      "W0404 08:30:48.522166   235 _caffe.cpp:173] Use this instead (with the named \"weights\" parameter):\n",
      "W0404 08:30:48.522181   235 _caffe.cpp:175] Net('/dli/data/digits/20190404-082321-ad38/deploy.prototxt', 1, weights='/dli/data/digits/20190404-082321-ad38/snapshot_iter_270.caffemodel')\n",
      "I0404 08:30:48.522518   235 upgrade_proto.cpp:66] Attempting to upgrade input file specified using deprecated input fields: /dli/data/digits/20190404-082321-ad38/deploy.prototxt\n",
      "I0404 08:30:48.522552   235 upgrade_proto.cpp:69] Successfully upgraded file specified using deprecated input fields.\n",
      "W0404 08:30:48.522562   235 upgrade_proto.cpp:71] Note that future Caffe releases will only support input layers and not input fields.\n",
      "I0404 08:30:48.532150   235 net.cpp:79] Initializing net from parameters: \n",
      "state {\n",
      "  phase: TEST\n",
      "  level: 0\n",
      "}\n",
      "layer {\n",
      "  name: \"input\"\n",
      "  type: \"Input\"\n",
      "  top: \"data\"\n",
      "  input_param {\n",
      "    shape {\n",
      "      dim: 1\n",
      "      dim: 3\n",
      "      dim: 227\n",
      "      dim: 227\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv1\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"data\"\n",
      "  top: \"conv1\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 96\n",
      "    kernel_size: 11\n",
      "    stride: 4\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu1\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"conv1\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm1\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv1\"\n",
      "  top: \"norm1\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool1\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm1\"\n",
      "  top: \"pool1\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv2\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool1\"\n",
      "  top: \"conv2\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 2\n",
      "    kernel_size: 5\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu2\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"conv2\"\n",
      "}\n",
      "layer {\n",
      "  name: \"norm2\"\n",
      "  type: \"LRN\"\n",
      "  bottom: \"conv2\"\n",
      "  top: \"norm2\"\n",
      "  lrn_param {\n",
      "    local_size: 5\n",
      "    alpha: 0.0001\n",
      "    beta: 0.75\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"pool2\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"norm2\"\n",
      "  top: \"pool2\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"conv3\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"pool2\"\n",
      "  top: \"conv3\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu3\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv3\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv4\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv3\"\n",
      "  top: \"conv4\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 384\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu4\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv4\"\n",
      "}\n",
      "layer {\n",
      "  name: \"conv5\"\n",
      "  type: \"Convolution\"\n",
      "  bottom: \"conv4\"\n",
      "  top: \"conv5\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  convolution_param {\n",
      "    num_output: 256\n",
      "    pad: 1\n",
      "    kernel_size: 3\n",
      "    group: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu5\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"conv5\"\n",
      "}\n",
      "layer {\n",
      "  name: \"pool5\"\n",
      "  type: \"Pooling\"\n",
      "  bottom: \"conv5\"\n",
      "  top: \"pool5\"\n",
      "  pooling_param {\n",
      "    pool: MAX\n",
      "    kernel_size: 3\n",
      "    stride: 2\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc6\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"pool5\"\n",
      "  top: \"fc6\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu6\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop6\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc6\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc7\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc6\"\n",
      "  top: \"fc7\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 4096\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.005\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0.1\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"relu7\"\n",
      "  type: \"ReLU\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "}\n",
      "layer {\n",
      "  name: \"drop7\"\n",
      "  type: \"Dropout\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc7\"\n",
      "  dropout_param {\n",
      "    dropout_ratio: 0.5\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"fc8\"\n",
      "  type: \"InnerProduct\"\n",
      "  bottom: \"fc7\"\n",
      "  top: \"fc8\"\n",
      "  param {\n",
      "    lr_mult: 1\n",
      "    decay_mult: 1\n",
      "  }\n",
      "  param {\n",
      "    lr_mult: 2\n",
      "    decay_mult: 0\n",
      "  }\n",
      "  inner_product_param {\n",
      "    num_output: 2\n",
      "    weight_filler {\n",
      "      type: \"gaussian\"\n",
      "      std: 0.01\n",
      "    }\n",
      "    bias_filler {\n",
      "      type: \"constant\"\n",
      "      value: 0\n",
      "    }\n",
      "  }\n",
      "}\n",
      "layer {\n",
      "  name: \"softmax\"\n",
      "  type: \"Softmax\"\n",
      "  bottom: \"fc8\"\n",
      "  top: \"softmax\"\n",
      "}\n",
      "I0404 08:30:48.532568   235 net.cpp:109] Using FLOAT as default forward math type\n",
      "I0404 08:30:48.532588   235 net.cpp:115] Using FLOAT as default backward math type\n",
      "I0404 08:30:48.532601   235 layer_factory.hpp:172] Creating layer 'input' of type 'Input'\n",
      "I0404 08:30:48.532613   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:48.532640   235 net.cpp:199] Created Layer input (0)\n",
      "I0404 08:30:48.532663   235 net.cpp:541] input -> data\n",
      "I0404 08:30:48.533355   235 net.cpp:259] Setting up input\n",
      "I0404 08:30:48.533392   235 net.cpp:266] TEST Top shape for layer 0 'input' 1 3 227 227 (154587)\n",
      "I0404 08:30:48.533416   235 layer_factory.hpp:172] Creating layer 'conv1' of type 'Convolution'\n",
      "I0404 08:30:48.533427   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:48.533464   235 net.cpp:199] Created Layer conv1 (1)\n",
      "I0404 08:30:48.533478   235 net.cpp:571] conv1 <- data\n",
      "I0404 08:30:48.533489   235 net.cpp:541] conv1 -> conv1\n",
      "I0404 08:30:49.058737   235 net.cpp:259] Setting up conv1\n",
      "I0404 08:30:49.058794   235 net.cpp:266] TEST Top shape for layer 1 'conv1' 1 96 55 55 (290400)\n",
      "I0404 08:30:49.058826   235 layer_factory.hpp:172] Creating layer 'relu1' of type 'ReLU'\n",
      "I0404 08:30:49.058845   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:49.058861   235 net.cpp:199] Created Layer relu1 (2)\n",
      "I0404 08:30:49.058874   235 net.cpp:571] relu1 <- conv1\n",
      "I0404 08:30:49.058897   235 net.cpp:526] relu1 -> conv1 (in-place)\n",
      "I0404 08:30:49.058935   235 net.cpp:259] Setting up relu1\n",
      "I0404 08:30:49.058951   235 net.cpp:266] TEST Top shape for layer 2 'relu1' 1 96 55 55 (290400)\n",
      "I0404 08:30:49.058964   235 layer_factory.hpp:172] Creating layer 'norm1' of type 'LRN'\n",
      "I0404 08:30:49.058974   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:49.059026   235 net.cpp:199] Created Layer norm1 (3)\n",
      "I0404 08:30:49.059041   235 net.cpp:571] norm1 <- conv1\n",
      "I0404 08:30:49.059052   235 net.cpp:541] norm1 -> norm1\n",
      "I0404 08:30:49.059119   235 net.cpp:259] Setting up norm1\n",
      "I0404 08:30:49.059141   235 net.cpp:266] TEST Top shape for layer 3 'norm1' 1 96 55 55 (290400)\n",
      "I0404 08:30:49.059152   235 layer_factory.hpp:172] Creating layer 'pool1' of type 'Pooling'\n",
      "I0404 08:30:49.059168   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:49.059221   235 net.cpp:199] Created Layer pool1 (4)\n",
      "I0404 08:30:49.059239   235 net.cpp:571] pool1 <- norm1\n",
      "I0404 08:30:49.059252   235 net.cpp:541] pool1 -> pool1\n",
      "I0404 08:30:49.059329   235 net.cpp:259] Setting up pool1\n",
      "I0404 08:30:49.059350   235 net.cpp:266] TEST Top shape for layer 4 'pool1' 1 96 27 27 (69984)\n",
      "I0404 08:30:49.059361   235 layer_factory.hpp:172] Creating layer 'conv2' of type 'Convolution'\n",
      "I0404 08:30:49.059378   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:49.059406   235 net.cpp:199] Created Layer conv2 (5)\n",
      "I0404 08:30:49.059419   235 net.cpp:571] conv2 <- pool1\n",
      "I0404 08:30:49.059432   235 net.cpp:541] conv2 -> conv2\n",
      "I0404 08:30:49.066593   235 net.cpp:259] Setting up conv2\n",
      "I0404 08:30:49.066632   235 net.cpp:266] TEST Top shape for layer 5 'conv2' 1 256 27 27 (186624)\n",
      "I0404 08:30:49.066658   235 layer_factory.hpp:172] Creating layer 'relu2' of type 'ReLU'\n",
      "I0404 08:30:49.066676   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:49.066694   235 net.cpp:199] Created Layer relu2 (6)\n",
      "I0404 08:30:49.066710   235 net.cpp:571] relu2 <- conv2\n",
      "I0404 08:30:49.066723   235 net.cpp:526] relu2 -> conv2 (in-place)\n",
      "I0404 08:30:49.066746   235 net.cpp:259] Setting up relu2\n",
      "I0404 08:30:49.066761   235 net.cpp:266] TEST Top shape for layer 6 'relu2' 1 256 27 27 (186624)\n",
      "I0404 08:30:49.066772   235 layer_factory.hpp:172] Creating layer 'norm2' of type 'LRN'\n",
      "I0404 08:30:49.066782   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:49.066803   235 net.cpp:199] Created Layer norm2 (7)\n",
      "I0404 08:30:49.066818   235 net.cpp:571] norm2 <- conv2\n",
      "I0404 08:30:49.066829   235 net.cpp:541] norm2 -> norm2\n",
      "I0404 08:30:49.066891   235 net.cpp:259] Setting up norm2\n",
      "I0404 08:30:49.066911   235 net.cpp:266] TEST Top shape for layer 7 'norm2' 1 256 27 27 (186624)\n",
      "I0404 08:30:49.066923   235 layer_factory.hpp:172] Creating layer 'pool2' of type 'Pooling'\n",
      "I0404 08:30:49.066939   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:49.066958   235 net.cpp:199] Created Layer pool2 (8)\n",
      "I0404 08:30:49.066973   235 net.cpp:571] pool2 <- norm2\n",
      "I0404 08:30:49.067013   235 net.cpp:541] pool2 -> pool2\n",
      "I0404 08:30:49.067082   235 net.cpp:259] Setting up pool2\n",
      "I0404 08:30:49.067101   235 net.cpp:266] TEST Top shape for layer 8 'pool2' 1 256 13 13 (43264)\n",
      "I0404 08:30:49.067113   235 layer_factory.hpp:172] Creating layer 'conv3' of type 'Convolution'\n",
      "I0404 08:30:49.067131   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:49.067155   235 net.cpp:199] Created Layer conv3 (9)\n",
      "I0404 08:30:49.067168   235 net.cpp:571] conv3 <- pool2\n",
      "I0404 08:30:49.067180   235 net.cpp:541] conv3 -> conv3\n",
      "I0404 08:30:49.082798   235 net.cpp:259] Setting up conv3\n",
      "I0404 08:30:49.082831   235 net.cpp:266] TEST Top shape for layer 9 'conv3' 1 384 13 13 (64896)\n",
      "I0404 08:30:49.082855   235 layer_factory.hpp:172] Creating layer 'relu3' of type 'ReLU'\n",
      "I0404 08:30:49.082875   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:49.082892   235 net.cpp:199] Created Layer relu3 (10)\n",
      "I0404 08:30:49.082903   235 net.cpp:571] relu3 <- conv3\n",
      "I0404 08:30:49.082916   235 net.cpp:526] relu3 -> conv3 (in-place)\n",
      "I0404 08:30:49.082932   235 net.cpp:259] Setting up relu3\n",
      "I0404 08:30:49.082949   235 net.cpp:266] TEST Top shape for layer 10 'relu3' 1 384 13 13 (64896)\n",
      "I0404 08:30:49.082962   235 layer_factory.hpp:172] Creating layer 'conv4' of type 'Convolution'\n",
      "I0404 08:30:49.082973   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:49.083019   235 net.cpp:199] Created Layer conv4 (11)\n",
      "I0404 08:30:49.083034   235 net.cpp:571] conv4 <- conv3\n",
      "I0404 08:30:49.083045   235 net.cpp:541] conv4 -> conv4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0404 08:30:49.095360   235 net.cpp:259] Setting up conv4\n",
      "I0404 08:30:49.095392   235 net.cpp:266] TEST Top shape for layer 11 'conv4' 1 384 13 13 (64896)\n",
      "I0404 08:30:49.095450   235 layer_factory.hpp:172] Creating layer 'relu4' of type 'ReLU'\n",
      "I0404 08:30:49.095464   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:49.095479   235 net.cpp:199] Created Layer relu4 (12)\n",
      "I0404 08:30:49.095495   235 net.cpp:571] relu4 <- conv4\n",
      "I0404 08:30:49.095508   235 net.cpp:526] relu4 -> conv4 (in-place)\n",
      "I0404 08:30:49.095530   235 net.cpp:259] Setting up relu4\n",
      "I0404 08:30:49.095544   235 net.cpp:266] TEST Top shape for layer 12 'relu4' 1 384 13 13 (64896)\n",
      "I0404 08:30:49.095556   235 layer_factory.hpp:172] Creating layer 'conv5' of type 'Convolution'\n",
      "I0404 08:30:49.095566   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:49.095592   235 net.cpp:199] Created Layer conv5 (13)\n",
      "I0404 08:30:49.095604   235 net.cpp:571] conv5 <- conv4\n",
      "I0404 08:30:49.095615   235 net.cpp:541] conv5 -> conv5\n",
      "I0404 08:30:49.103646   235 net.cpp:259] Setting up conv5\n",
      "I0404 08:30:49.103674   235 net.cpp:266] TEST Top shape for layer 13 'conv5' 1 256 13 13 (43264)\n",
      "I0404 08:30:49.103698   235 layer_factory.hpp:172] Creating layer 'relu5' of type 'ReLU'\n",
      "I0404 08:30:49.103716   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:49.103731   235 net.cpp:199] Created Layer relu5 (14)\n",
      "I0404 08:30:49.103749   235 net.cpp:571] relu5 <- conv5\n",
      "I0404 08:30:49.103760   235 net.cpp:526] relu5 -> conv5 (in-place)\n",
      "I0404 08:30:49.103776   235 net.cpp:259] Setting up relu5\n",
      "I0404 08:30:49.103794   235 net.cpp:266] TEST Top shape for layer 14 'relu5' 1 256 13 13 (43264)\n",
      "I0404 08:30:49.103816   235 layer_factory.hpp:172] Creating layer 'pool5' of type 'Pooling'\n",
      "I0404 08:30:49.103830   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:49.103852   235 net.cpp:199] Created Layer pool5 (15)\n",
      "I0404 08:30:49.103863   235 net.cpp:571] pool5 <- conv5\n",
      "I0404 08:30:49.103878   235 net.cpp:541] pool5 -> pool5\n",
      "I0404 08:30:49.103955   235 net.cpp:259] Setting up pool5\n",
      "I0404 08:30:49.103973   235 net.cpp:266] TEST Top shape for layer 15 'pool5' 1 256 6 6 (9216)\n",
      "I0404 08:30:49.103981   235 layer_factory.hpp:172] Creating layer 'fc6' of type 'InnerProduct'\n",
      "I0404 08:30:49.103988   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:49.104007   235 net.cpp:199] Created Layer fc6 (16)\n",
      "I0404 08:30:49.104018   235 net.cpp:571] fc6 <- pool5\n",
      "I0404 08:30:49.104027   235 net.cpp:541] fc6 -> fc6\n",
      "I0404 08:30:49.779103   235 net.cpp:259] Setting up fc6\n",
      "I0404 08:30:49.779156   235 net.cpp:266] TEST Top shape for layer 16 'fc6' 1 4096 (4096)\n",
      "I0404 08:30:49.779178   235 layer_factory.hpp:172] Creating layer 'relu6' of type 'ReLU'\n",
      "I0404 08:30:49.779194   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:49.779208   235 net.cpp:199] Created Layer relu6 (17)\n",
      "I0404 08:30:49.779222   235 net.cpp:571] relu6 <- fc6\n",
      "I0404 08:30:49.779232   235 net.cpp:526] relu6 -> fc6 (in-place)\n",
      "I0404 08:30:49.779253   235 net.cpp:259] Setting up relu6\n",
      "I0404 08:30:49.779265   235 net.cpp:266] TEST Top shape for layer 17 'relu6' 1 4096 (4096)\n",
      "I0404 08:30:49.779273   235 layer_factory.hpp:172] Creating layer 'drop6' of type 'Dropout'\n",
      "I0404 08:30:49.779284   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:49.779297   235 net.cpp:199] Created Layer drop6 (18)\n",
      "I0404 08:30:49.779307   235 net.cpp:571] drop6 <- fc6\n",
      "I0404 08:30:49.779314   235 net.cpp:526] drop6 -> fc6 (in-place)\n",
      "I0404 08:30:49.813885   235 net.cpp:259] Setting up drop6\n",
      "I0404 08:30:49.813946   235 net.cpp:266] TEST Top shape for layer 18 'drop6' 1 4096 (4096)\n",
      "I0404 08:30:49.813969   235 layer_factory.hpp:172] Creating layer 'fc7' of type 'InnerProduct'\n",
      "I0404 08:30:49.813990   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:49.814015   235 net.cpp:199] Created Layer fc7 (19)\n",
      "I0404 08:30:49.814065   235 net.cpp:571] fc7 <- fc6\n",
      "I0404 08:30:49.814079   235 net.cpp:541] fc7 -> fc7\n",
      "I0404 08:30:50.114078   235 net.cpp:259] Setting up fc7\n",
      "I0404 08:30:50.114128   235 net.cpp:266] TEST Top shape for layer 19 'fc7' 1 4096 (4096)\n",
      "I0404 08:30:50.114150   235 layer_factory.hpp:172] Creating layer 'relu7' of type 'ReLU'\n",
      "I0404 08:30:50.114164   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:50.114179   235 net.cpp:199] Created Layer relu7 (20)\n",
      "I0404 08:30:50.114192   235 net.cpp:571] relu7 <- fc7\n",
      "I0404 08:30:50.114215   235 net.cpp:526] relu7 -> fc7 (in-place)\n",
      "I0404 08:30:50.114245   235 net.cpp:259] Setting up relu7\n",
      "I0404 08:30:50.114264   235 net.cpp:266] TEST Top shape for layer 20 'relu7' 1 4096 (4096)\n",
      "I0404 08:30:50.114275   235 layer_factory.hpp:172] Creating layer 'drop7' of type 'Dropout'\n",
      "I0404 08:30:50.114291   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:50.114311   235 net.cpp:199] Created Layer drop7 (21)\n",
      "I0404 08:30:50.114325   235 net.cpp:571] drop7 <- fc7\n",
      "I0404 08:30:50.114334   235 net.cpp:526] drop7 -> fc7 (in-place)\n",
      "I0404 08:30:50.148929   235 net.cpp:259] Setting up drop7\n",
      "I0404 08:30:50.148967   235 net.cpp:266] TEST Top shape for layer 21 'drop7' 1 4096 (4096)\n",
      "I0404 08:30:50.148983   235 layer_factory.hpp:172] Creating layer 'fc8' of type 'InnerProduct'\n",
      "I0404 08:30:50.148999   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:50.149021   235 net.cpp:199] Created Layer fc8 (22)\n",
      "I0404 08:30:50.149036   235 net.cpp:571] fc8 <- fc7\n",
      "I0404 08:30:50.149049   235 net.cpp:541] fc8 -> fc8\n",
      "I0404 08:30:50.150035   235 net.cpp:259] Setting up fc8\n",
      "I0404 08:30:50.150064   235 net.cpp:266] TEST Top shape for layer 22 'fc8' 1 2 (2)\n",
      "I0404 08:30:50.150085   235 layer_factory.hpp:172] Creating layer 'softmax' of type 'Softmax'\n",
      "I0404 08:30:50.150099   235 layer_factory.hpp:184] Layer's types are Ftype:FLOAT Btype:FLOAT Fmath:FLOAT Bmath:FLOAT\n",
      "I0404 08:30:50.150122   235 net.cpp:199] Created Layer softmax (23)\n",
      "I0404 08:30:50.150138   235 net.cpp:571] softmax <- fc8\n",
      "I0404 08:30:50.150151   235 net.cpp:541] softmax -> softmax\n",
      "I0404 08:30:50.150249   235 net.cpp:259] Setting up softmax\n",
      "I0404 08:30:50.150267   235 net.cpp:266] TEST Top shape for layer 23 'softmax' 1 2 (2)\n",
      "I0404 08:30:50.150279   235 net.cpp:337] softmax does not need backward computation.\n",
      "I0404 08:30:50.150296   235 net.cpp:337] fc8 does not need backward computation.\n",
      "I0404 08:30:50.150305   235 net.cpp:337] drop7 does not need backward computation.\n",
      "I0404 08:30:50.150321   235 net.cpp:337] relu7 does not need backward computation.\n",
      "I0404 08:30:50.150331   235 net.cpp:337] fc7 does not need backward computation.\n",
      "I0404 08:30:50.150341   235 net.cpp:337] drop6 does not need backward computation.\n",
      "I0404 08:30:50.150348   235 net.cpp:337] relu6 does not need backward computation.\n",
      "I0404 08:30:50.150362   235 net.cpp:337] fc6 does not need backward computation.\n",
      "I0404 08:30:50.150373   235 net.cpp:337] pool5 does not need backward computation.\n",
      "I0404 08:30:50.150383   235 net.cpp:337] relu5 does not need backward computation.\n",
      "I0404 08:30:50.150393   235 net.cpp:337] conv5 does not need backward computation.\n",
      "I0404 08:30:50.150403   235 net.cpp:337] relu4 does not need backward computation.\n",
      "I0404 08:30:50.150416   235 net.cpp:337] conv4 does not need backward computation.\n",
      "I0404 08:30:50.150426   235 net.cpp:337] relu3 does not need backward computation.\n",
      "I0404 08:30:50.150436   235 net.cpp:337] conv3 does not need backward computation.\n",
      "I0404 08:30:50.150446   235 net.cpp:337] pool2 does not need backward computation.\n",
      "I0404 08:30:50.150458   235 net.cpp:337] norm2 does not need backward computation.\n",
      "I0404 08:30:50.150467   235 net.cpp:337] relu2 does not need backward computation.\n",
      "I0404 08:30:50.150481   235 net.cpp:337] conv2 does not need backward computation.\n",
      "I0404 08:30:50.150491   235 net.cpp:337] pool1 does not need backward computation.\n",
      "I0404 08:30:50.150533   235 net.cpp:337] norm1 does not need backward computation.\n",
      "I0404 08:30:50.150544   235 net.cpp:337] relu1 does not need backward computation.\n",
      "I0404 08:30:50.150553   235 net.cpp:337] conv1 does not need backward computation.\n",
      "I0404 08:30:50.150564   235 net.cpp:337] input does not need backward computation.\n",
      "I0404 08:30:50.150573   235 net.cpp:379] This network produces output softmax\n",
      "I0404 08:30:50.150605   235 net.cpp:402] Top memory (TEST) required for data: 8315264 diff: 8315264\n",
      "I0404 08:30:50.150619   235 net.cpp:405] Bottom memory (TEST) required for data: 8315256 diff: 8315256\n",
      "I0404 08:30:50.150629   235 net.cpp:408] Shared (in-place) memory (TEST) by data: 2665856 diff: 2665856\n",
      "I0404 08:30:50.150638   235 net.cpp:411] Parameters memory (TEST) required for data: 227505672 diff: 227505672\n",
      "I0404 08:30:50.150648   235 net.cpp:414] Parameters shared memory (TEST) by data: 0 diff: 0\n",
      "I0404 08:30:50.150656   235 net.cpp:420] Network initialization done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I0404 08:30:50.259029   235 net.cpp:1129] Ignoring source layer train-data\n",
      "I0404 08:30:50.259078   235 net.cpp:1137] Copying source layer conv1 Type:Convolution #blobs=2\n",
      "I0404 08:30:50.259181   235 net.cpp:1137] Copying source layer relu1 Type:ReLU #blobs=0\n",
      "I0404 08:30:50.259198   235 net.cpp:1137] Copying source layer norm1 Type:LRN #blobs=0\n",
      "I0404 08:30:50.259208   235 net.cpp:1137] Copying source layer pool1 Type:Pooling #blobs=0\n",
      "I0404 08:30:50.259218   235 net.cpp:1137] Copying source layer conv2 Type:Convolution #blobs=2\n",
      "I0404 08:30:50.259397   235 net.cpp:1137] Copying source layer relu2 Type:ReLU #blobs=0\n",
      "I0404 08:30:50.259413   235 net.cpp:1137] Copying source layer norm2 Type:LRN #blobs=0\n",
      "I0404 08:30:50.259423   235 net.cpp:1137] Copying source layer pool2 Type:Pooling #blobs=0\n",
      "I0404 08:30:50.259433   235 net.cpp:1137] Copying source layer conv3 Type:Convolution #blobs=2\n",
      "I0404 08:30:50.259891   235 net.cpp:1137] Copying source layer relu3 Type:ReLU #blobs=0\n",
      "I0404 08:30:50.259908   235 net.cpp:1137] Copying source layer conv4 Type:Convolution #blobs=2\n",
      "I0404 08:30:50.260260   235 net.cpp:1137] Copying source layer relu4 Type:ReLU #blobs=0\n",
      "I0404 08:30:50.260277   235 net.cpp:1137] Copying source layer conv5 Type:Convolution #blobs=2\n",
      "I0404 08:30:50.260517   235 net.cpp:1137] Copying source layer relu5 Type:ReLU #blobs=0\n",
      "I0404 08:30:50.260534   235 net.cpp:1137] Copying source layer pool5 Type:Pooling #blobs=0\n",
      "I0404 08:30:50.260543   235 net.cpp:1137] Copying source layer fc6 Type:InnerProduct #blobs=2\n",
      "I0404 08:30:50.278729   235 net.cpp:1137] Copying source layer relu6 Type:ReLU #blobs=0\n",
      "I0404 08:30:50.278770   235 net.cpp:1137] Copying source layer drop6 Type:Dropout #blobs=0\n",
      "I0404 08:30:50.278779   235 net.cpp:1137] Copying source layer fc7 Type:InnerProduct #blobs=2\n",
      "I0404 08:30:50.286886   235 net.cpp:1137] Copying source layer relu7 Type:ReLU #blobs=0\n",
      "I0404 08:30:50.286919   235 net.cpp:1137] Copying source layer drop7 Type:Dropout #blobs=0\n",
      "I0404 08:30:50.286928   235 net.cpp:1137] Copying source layer fc8 Type:InnerProduct #blobs=2\n",
      "I0404 08:30:50.286964   235 net.cpp:1129] Ignoring source layer loss\n",
      "not whale\n"
     ]
    }
   ],
   "source": [
    "!python submission.py '/dli/data/whale/data/train/not_face/w_1.jpg'  #This should return \"not whale\" at the very bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caffe_output.log\t      snapshot_iter_270.caffemodel\r\n",
      "deploy.prototxt\t\t      snapshot_iter_270.solverstate\r\n",
      "original.prototxt\t      snapshot_iter_54.caffemodel\r\n",
      "snapshot_iter_108.caffemodel  solver.prototxt\r\n",
      "snapshot_iter_162.caffemodel  status.pickle\r\n",
      "snapshot_iter_216.caffemodel  train_val.prototxt\r\n"
     ]
    }
   ],
   "source": [
    "!ls /dli/data/digits/20190404-082321-ad38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "Assessment1.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
